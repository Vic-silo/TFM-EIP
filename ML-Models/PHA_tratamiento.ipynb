{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf08755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer ficheros de datos\n",
    "import codecs\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "# Extraer información\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "# Auxiliares\n",
    "import numpy as np\n",
    "import logging\n",
    "from typing import Union\n",
    "import pyarrow as pa\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import KNNImputer, IterativeImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04f3c21",
   "metadata": {},
   "source": [
    "### Cargamos el parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20c61b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('Datasets/PHA/PHA_Data.parquet', engine='pyarrow')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911dbbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff37343",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['c55']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "61015bcb",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Crear un boxplot de una sola columna del dataframe\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.boxplot(data['c55'])\n",
    "\n",
    "# Personalizar el gráfico\n",
    "ax.set_title('Boxplot de la columna')\n",
    "ax.set_ylabel('Valores')\n",
    "plt.ylim(3880, 3900)\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ff78c271",
   "metadata": {},
   "source": [
    "df_filtrado = drop.df[(df['c55'] >= 3000) & (df['c55'] <= 4000)]\n",
    "df_filtrado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0a875a",
   "metadata": {},
   "source": [
    "### Convertimos cualquier tipo de registro faltante a NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8195ea2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(value): \n",
    "    # Si se trata de un valor en blanco sustituir a NaN \n",
    "    try: \n",
    "        if value in [None, 'nan']: \n",
    "            return np.nan \n",
    "         \n",
    "        return value \n",
    " \n",
    "    except Exception as e: \n",
    "        return value \n",
    "     \n",
    "# Iterar sobre todas las columnas y comprobar sus valores \n",
    "columns = len(df.columns) \n",
    " \n",
    "for column in df.columns: \n",
    "    # Utilizar compresion de listas y aplicar el filtrado de valores \n",
    "    values = [clean_data(value) for value in df[column]] \n",
    "    df[column] = values \n",
    "    columns -= 1 \n",
    "    print(f'[+] REMAINING_COLUMNS\\t{columns}\\t', end='\\r') \n",
    "     \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaf537d",
   "metadata": {},
   "source": [
    "### Cargamos cabecera  y convertimos a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b7fa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_legend = 'https://av-info.faa.gov/data/AID/Afilelayout.txt'\n",
    "# Leemos el contenido de la leyenda\n",
    "with urlopen(url_legend) as content:\n",
    "    soup = BeautifulSoup(content, \"html.parser\")\n",
    "    soup_lines = str(soup).split('\\r\\n')\n",
    "\n",
    "# Transformamos la respuesta en un diccionario con el nombre de la columna y la descripción\n",
    "legend_df = {\"Column_name\": [], \"Description\": []}\n",
    "# Recorrer las lineas con datos de lineas. Se salta las dos primeras y las tres ultimas\n",
    "# filas por no tener datos relevantes de la leyenda\n",
    "for line in soup_lines[2:-3]:\n",
    "    # Se extrae los 5 primeros caracteres para conocer el nombre de la columna\n",
    "    legend_df[\"Column_name\"].append(line[0:5].strip())\n",
    "    # Se extrae la descripcion, esta comienza en la posicion 53\n",
    "    legend_df[\"Description\"].append(line[53:].strip())\n",
    "    \n",
    "# Convertir el diccionario en pandas.Dataframe\n",
    "legend_df = pd.DataFrame.from_dict(data=legend_df)\n",
    "legend_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d6e5f4",
   "metadata": {},
   "source": [
    "### Enumeramos las cabecera con la descripción para poder verlas mejor y seleccionamos las columnas que podrían ser relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e162022a",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_columns = ['c76','c1', 'c6', 'c7', 'c8', 'c10', 'c132', 'c134', 'c136', 'c138', 'c141', 'c160', 'c162', 'c23', 'c24', 'c11', 'c14', 'c20', 'c21', 'c102', 'c104', 'c106', 'c108', 'c110', 'c114', 'c115', 'c117', 'c118', 'c61', 'c62', 'c65', 'c67', 'c68', 'c41', 'c45', 'c47', 'c49', 'c50', 'c52', 'c53', 'c54', 'c55', 'c56', 'c120', 'c121', 'c122', 'c126', 'c127', 'c128', 'c130', 'c78', 'c80', 'c82', 'c84', 'c86', 'c88', 'c90', 'c92', 'c94', 'c96', 'c44', 'c46', 'c48', 'c51', 'c229', 'c230']\n",
    "#used_columns = [f'c{idx}' for idx in used_columns]\n",
    "\n",
    "for col in used_columns:\n",
    "    description = legend_df[legend_df[\"Column_name\"] == col][\"Description\"].values[0]\n",
    "    print(f'[+]  Descripción columnas\\t{col}\\t{description}')\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52feac5",
   "metadata": {},
   "source": [
    "### Creamos dataframe a partir del primario usando solamente las columnas de la lista anteriormente  generada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5f304b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= df.loc[:, used_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a71dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_values = data['c76'].value_counts()\n",
    "repeated_values_df = repeated_values.to_frame()\n",
    "repeated_values_df.columns = ['Frequency']\n",
    "print(repeated_values_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180a2e00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5783e92",
   "metadata": {},
   "source": [
    "### Realizamos un conteo de los datos faltantes NaN de las columnas que pueden ser potenciales"
   ]
  },
  {
   "cell_type": "raw",
   "id": "69ca3fa8",
   "metadata": {},
   "source": [
    "\n",
    "# Configurar el tamaño de la figura\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Crear un mapa de calor para visualizar los valores faltantes\n",
    "sns.heatmap(data.isna(), cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ef6ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar el número de valores NaN en cada columna\n",
    "print(data.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78899b38",
   "metadata": {},
   "source": [
    "### Procedemos a borrar las columnas con demasiados datos faltantes (más de 100.000 unidades) y las filas que tengan más de 3 valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2f24f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Borramos columnas que tengan más de 100.000 datos faltantes  \n",
    "data = data.dropna(thresh=100000, axis=1)\n",
    "data = data.dropna(thresh=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9504de",
   "metadata": {},
   "source": [
    "### Volvemos a contar despues del borrado para ver que columnas son aprovechables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346639a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar el número de valores NaN en cada columna\n",
    "print(data.isna().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962e20a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = list(data.columns)\n",
    "#unused_columns = [5, 3, 2, 4, 9, 75, 140, 139, 203, 204, 214, 790, 26, 37, 15, 16, 17,18, 19, 143, 205, 206, 207, 208, 210, 43, 129, 124, 125, 77]\n",
    "#unused_columns = [f'c{idx}' for idx in unused_columns]\n",
    "\n",
    "for col in columnas:\n",
    "    description = legend_df[legend_df[\"Column_name\"] == col][\"Description\"].values[0]\n",
    "    print(f'[+] Descripción columnas\\t{col}\\t{description}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3261d4b",
   "metadata": {},
   "source": [
    "# ESTUDIO DE COLUMNAS PARA SABER CUALES SON CATEGORICAS Y CUALES NUMERICAS PARA PROCEDER SEGUIDAMENTE A LA IMPUTACIÓN\n",
    "\n",
    "Si se optara por hacerlo de forma automatica hay atributos que se clasificaran como categoricos cuando no lo son y viceversa\n",
    "Por lo que hay que proceder a hacerlo manualmente mediante dos pasos:\n",
    "En el primer paso se comprueba la cantidad de valores unicos clasificando los que superan los 100 valores como numericos. \n",
    "En segundo lugar hay que comprobar que los valores no unicos no contengan string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4267d1",
   "metadata": {},
   "source": [
    "### Primer paso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d4799b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# con  un sencillo for podemos apreciar la cantidad de valores unicos de cada columna\n",
    "# vamos a establecer que los que tengan más de 100 valores unicos son numericos y los restantes categoricos\n",
    "\n",
    "for col in data.columns:\n",
    "    print(col, data[col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7be569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a establecer como criterio de clasificación las que superen 100 caracteres unicos serán numericas\n",
    "#las restantes serán categoricas\n",
    "\n",
    "# Definimos una lista para almacenar las columnas numéricas\n",
    "num_cols = []\n",
    "\n",
    "# Definimos una lista para almacenar las columnas categóricas\n",
    "cat_cols = []\n",
    "\n",
    "# Verificamos la cardinalidad de cada columna\n",
    "for col in data.columns:\n",
    "    unique_vals = data[col].nunique()\n",
    "    if unique_vals >= 100:\n",
    "        num_cols.append(col)\n",
    "    else:\n",
    "        cat_cols.append(col)\n",
    "\n",
    "# Imprimimos las columnas numéricas y categóricas\n",
    "print(\"Columnas numéricas:\", num_cols)\n",
    "print(\"Columnas categóricas:\", cat_cols)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d3c31381",
   "metadata": {},
   "source": [
    "#############################################################################################################\n",
    "############# No se puede realizar comprobación ya que contienen valores NaN que antes hay que imputar########\n",
    "#############################################################################################################\n",
    "#ahora vamos a verificar que las que se han clasificado como numericas no contengan caracteres string \n",
    "#de ser así no pueden ser numericas y pasarian a categoricas\n",
    "for col in numeric_cols:\n",
    "    try:\n",
    "        pd.to_numeric(df[col])\n",
    "    except ValueError:\n",
    "        non_numeric_count = df[col].apply(lambda x: not pd.api.types.is_numeric_dtype(x)).sum()\n",
    "        print(f\"La columna '{col}' contiene {non_numeric_count} valores no numéricos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7584c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in num_cols:\n",
    "    try:\n",
    "        numeric_values = pd.to_numeric(data[col])\n",
    "        non_numeric_values = numeric_values.isna().sum()\n",
    "        print(f\"La columna '{col}' tiene {non_numeric_values} valores no numéricos (excluyendo NaN)\")\n",
    "    except ValueError:\n",
    "        print(f\"La columna '{col}' contiene valores no numéricos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285a1846",
   "metadata": {},
   "source": [
    "### Segundo paso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c340074",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in num_cols:\n",
    "    print(data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2b3ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cat_cols:\n",
    "    print(data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12d0bc2",
   "metadata": {},
   "source": [
    "Hay que añadir las columnas con  texto es decir que no son tipo numerico y pasarlas a categoricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2c1a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols=['c76','c1', 'c6', 'c7', 'c8', 'c132', 'c134', 'c141', 'c11', 'c102', 'c104', 'c106', 'c108', 'c110', 'c65', 'c67', 'c68', 'c41', 'c45', 'c47', 'c49', 'c50', 'c52', 'c130', 'c80', 'c82', 'c94', 'c96', 'c44', 'c46', 'c48', 'c51','c23','c24','c14','c78']\n",
    "num_cols= ['c10', 'c61', 'c62', 'c53', 'c54', 'c55', 'c56']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a223b1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc6a5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Aplicar la conversión en la columna 'A' usando apply y una función lambda\n",
    "data['c76'] = data['c76'].apply(lambda x: 0 if x <= 3 else 1)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf25ce2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "793bccd1",
   "metadata": {},
   "source": [
    "import re\n",
    "patron = re.compile(r'[^\\w\\s.,ñáéíóú,$]')\n",
    "for columna in data.columns:\n",
    "    for indice, valor in data[columna].iteritems():\n",
    "        # Buscar caracteres raros en la celda actual\n",
    "        resultado = patron.search(str(valor))\n",
    "        if resultado:\n",
    "            print(f\"Caracter raro encontrado en la columna {columna}, fila {indice}: '{resultado.group(0)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd38d84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"c10\"] = data[\"c10\"].apply(pd.to_numeric, downcast='float', errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c999b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['c10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6e2c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efb9aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_values = data['c76'].value_counts()\n",
    "repeated_values_df = repeated_values.to_frame()\n",
    "repeated_values_df.columns = ['Frequency']\n",
    "print(repeated_values_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc039a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5fccd7",
   "metadata": {},
   "source": [
    "# Imputación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9cfd78",
   "metadata": {},
   "source": [
    "## Imputación simple y menos precisa"
   ]
  },
  {
   "cell_type": "raw",
   "id": "373b469e",
   "metadata": {},
   "source": [
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "# Imputación para columnas numéricas\n",
    "#num_cols = data.select_dtypes(include=['float', 'int']).columns.tolist()\n",
    "num_cols = numeric_cols\n",
    "num_imputer = SimpleImputer(strategy='mean')\n",
    "data[num_cols] = num_imputer.fit_transform(data[num_cols])\n",
    "\n",
    "# Imputación para columnas categóricas\n",
    "cat_cols = data.select_dtypes(include=['object']).columns.tolist()\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "data[cat_cols] = cat_imputer.fit_transform(data[cat_cols])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988e1029",
   "metadata": {},
   "source": [
    "## Imputación más exacta pero más costosa computacionalmente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f95e6c",
   "metadata": {},
   "source": [
    "#### Imputación de columnas  numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f495181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer, IterativeImputer\n",
    "\n",
    "# Imputación para columnas numéricas\n",
    "#num_cols = data.select_dtypes(include=['float', 'int']).columns.tolist()\n",
    "num_imputer = KNNImputer(n_neighbors=5)\n",
    "data[num_cols] = num_imputer.fit_transform(data[num_cols])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5f0d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[num_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4addaaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426c49b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[cat_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dacb55",
   "metadata": {},
   "source": [
    "#### Imputación de columnas categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b351d4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"c76\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb64629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df_imputed = data\n",
    "# Imputación de valores categóricos\n",
    "#cat_cols = data.select_dtypes(include='object').columns.tolist()\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_imputed[col] = le.fit_transform(df_imputed[col].astype(str))\n",
    "\n",
    "imputer = KNNImputer()\n",
    "df_imputed[cat_cols] = imputer.fit_transform(df_imputed[cat_cols])\n",
    "\n",
    "# Convertir de vuelta a valores categóricos\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df_imputed[col].astype(int))\n",
    "    df_imputed[col] = le.inverse_transform(df_imputed[col].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9c5e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27040bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"c76\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68ec4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee617ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.isna().sum())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027431dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e0dd6a25",
   "metadata": {},
   "source": [
    "################################################\n",
    "#############Inputacion alternativa#############\n",
    "################################################\n",
    "\n",
    "# Imputación para columnas categóricas\n",
    "cat_cols = data.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "for col in cat_cols:\n",
    "    # Dividir el DataFrame en dos partes: una con valores conocidos y otra con valores faltantes\n",
    "    known = data[data[col].notnull()]\n",
    "    unknown = data[data[col].isnull()]\n",
    "    \n",
    "    # Separar la columna objetivo de la columna de características\n",
    "    target = known[col]\n",
    "    features = known.drop(columns=[col])\n",
    "    \n",
    "    # Entrenar el modelo de Random Forest\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(features, target)\n",
    "    \n",
    "    # Imputar los valores faltantes utilizando el modelo de Random Forest\n",
    "    imputed = rf.predict(unknown.drop(columns=[col]))\n",
    "    data.loc[data[col].isnull(), col] = imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd87b959",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.columns:\n",
    "    print(col, data[col].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387f9928",
   "metadata": {},
   "source": [
    "# Pasamos a parquet con los datos ya imputados para no tener que imputarlo cada vez que utilicemos el código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcc4bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_parquet(\"data_tratamiento.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab784800",
   "metadata": {},
   "source": [
    "AL LEER EL PARQUET TODOS LOS ATRIBUTOS APARECEN COMO NUMERICOS O FLOAT Y NINGUNO CATEGORICO POR LO QUE TENDREMOS QUE VOLVER A INDICAR CUALES SON CATEGORICOS Y CULES NO"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b9e3dfb3",
   "metadata": {},
   "source": [
    "data = pd.read_parquet(\"archivo.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c51195",
   "metadata": {},
   "source": [
    "### Ver relación entre caracteristicas (uso de SKEW())para ver como se relacionan los atributos y poder ver también si presentan valores atipicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3c20e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer ficheros de datos\n",
    "import codecs\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "# Extraer información\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "# Auxiliares\n",
    "import numpy as np\n",
    "import logging\n",
    "from typing import Union\n",
    "import pyarrow as pa\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import KNNImputer, IterativeImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Leemos parquet y generamos dataframe para seguir trabajando con el\n",
    "data = pd.read_parquet('data_tratamiento.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f1df27",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f5e977",
   "metadata": {},
   "source": [
    "Podemos verque una de los atributos concretamente el c55 es posible que tenga un valor atípico dada la desviacion que tiene"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca37ba16",
   "metadata": {},
   "source": [
    "Seguidamente hacemos un boxplot para poder confirmar si presenta valores atipicos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee544de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un boxplot de una sola columna del dataframe\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.boxplot(data['c55'])\n",
    "\n",
    "# Personalizar el gráfico\n",
    "ax.set_title('Boxplot de la columna')\n",
    "ax.set_ylabel('Valores')\n",
    "plt.ylim(0, 4000)\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0a05a3",
   "metadata": {},
   "source": [
    "Efectivamente es muy posible, contaremos ahora la cantidad de filas en las que se repiten estos valores para poder ver si es algo frecuente o es algo puntual que tiene bastante probabilidad de ser valor erroneo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a53dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supongamos que la columna se llama 'nombre_columna' y está en el dataframe 'df'\n",
    "conteo = data['c55'].between(1200, 4000, inclusive=True).sum()\n",
    "\n",
    "print(f\"El número de filas con valor entre 2000 y 4000 es: {conteo} de {len(data)} filas totales del dataframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42e8de6",
   "metadata": {},
   "source": [
    "Procederemos a eliminar esos tres registros  que tomaremos como erroneos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56bc3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "columna = data['c55']\n",
    "mascara = columna.between(1200, 4000, inclusive=True)\n",
    "#mascara.count() \n",
    "data = data[~mascara].dropna()\n",
    "\n",
    "conteo = data['c55'].between(1200, 4000, inclusive=True).sum()\n",
    "print(f\"El número de filas con valor entre 2000 y 4000 es: {conteo} de {len(data)} filas totales del dataframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba65598",
   "metadata": {},
   "source": [
    "Tras el tratamiento a la posibilidad de valores erraticos debido a la desviación que presenta la columna c55 observamos que los datos son aparentemente correctos y es la naturaleza de los mismos la que produce esa desviación.C6 aparenta tener el mismo problema pero es también debido a que es una fecha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee0870f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2950b7d6",
   "metadata": {},
   "source": [
    "# Escalar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3ede4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "cat_cols=['c76','c1', 'c6', 'c7', 'c8', 'c132', 'c134', 'c141', 'c11', 'c102', 'c104', 'c106', 'c108', 'c110', 'c65', 'c67', 'c68', 'c41', 'c45', 'c47', 'c49', 'c50', 'c52', 'c130', 'c80', 'c82', 'c94', 'c96', 'c44', 'c46', 'c48', 'c51','c23','c24','c14','c78']\n",
    "num_cols= ['c10', 'c61', 'c62', 'c53', 'c54', 'c55', 'c56']\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df.dtypes)\n",
    "# Seleccionamos los atributos numéricos y los estandarizamos\n",
    "#num_cols = df.select_dtypes(include=['int', 'float']).columns\n",
    "scaler = StandardScaler()\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "\n",
    "# Creamos un nuevo dataframe con los datos categóricos y los datos numéricos estandarizados\n",
    "#cat_cols = df.select_dtypes(include=['object']).columns\n",
    "df = pd.concat([df[cat_cols], df[num_cols]], axis=1)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663ec4cd",
   "metadata": {},
   "source": [
    "Una vez ya realizado el tratamiento de los datos guardamos en un .parquet para proseguir con la predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b166f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_values = df['c76'].value_counts()\n",
    "repeated_values_df = repeated_values.to_frame()\n",
    "repeated_values_df.columns = ['Frequency']\n",
    "print(repeated_values_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5ded7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"data_tratamiento_escalado.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df12f4e",
   "metadata": {},
   "source": [
    "# Balancear el dataframe porque hay menos valores de accidente que de no accidentes en la variable objetivo c76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fa3c95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar los datos en un dataframe\n",
    "df = pd.read_parquet('data_tratamiento_escalado.parquet', engine='pyarrow')\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X = df.drop('c76', axis=1) # todas las columnas excepto la etiqueta\n",
    "y = df['c76']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Sobremuestrear la clase minoritaria en el conjunto de entrenamiento\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_train, y_train = oversampler.fit_resample(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d10d8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "298937    1\n",
       "298938    1\n",
       "298939    1\n",
       "298940    1\n",
       "298941    1\n",
       "Name: c76, Length: 298942, dtype: int32"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65a6b37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Frequency\n",
      "0     149471\n",
      "1     149471\n"
     ]
    }
   ],
   "source": [
    "repeated_values = y_train.value_counts()\n",
    "repeated_values_df = repeated_values.to_frame()\n",
    "repeated_values_df.columns = ['Frequency']\n",
    "print(repeated_values_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520484e7",
   "metadata": {},
   "source": [
    "# Predecir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f22da9a",
   "metadata": {},
   "source": [
    "Predicción ejecutada en keras por problemas de ejecución en equipo local"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1a1832",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/josepy/prediccion-final/edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "573d67c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 99.58%\n"
     ]
    }
   ],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Entrenar el modelo de Bosque Aleatorio\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones sobre el conjunto de prueba\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluar la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Precisión del modelo: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cc6266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
